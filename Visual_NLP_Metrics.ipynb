{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a5b216-140e-451f-9d66-f96417b5c0d9",
   "metadata": {},
   "source": [
    "<h2>Install Required Library</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec7b31-e13a-44d6-a0ea-a7438631eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "license = \"\"\n",
    "if license and \"json\" in license:\n",
    "    with open(license, \"r\") as creds_in:\n",
    "        creds = json.loads(creds_in.read())\n",
    "        for key in creds.keys():\n",
    "            os.environ[key] = creds[key]\n",
    "else:\n",
    "    raise Exception(\"License JSON File is not specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32203195-5897-4ad7-851d-f5a94d1f2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -q https://pypi.johnsnowlabs.com/$SPARK_OCR_SECRET/spark-ocr/spark_ocr-6.0.0rc2-py3-none-any.whl\n",
    "!pip install --upgrade -q https://pypi.johnsnowlabs.com/$SECRET/spark-nlp-jsl/spark_nlp_jsl-5.5.3-py3-none-any.whl\n",
    "!pip install -q spark-nlp==5.5.3\n",
    "!pip install -q pandas\n",
    "!pip install -q matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75494ab3-1e9b-4e56-b841-3489cf7e1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RESTART SESSION!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9382e-08df-42d5-bdd1-2e23afc1f4ff",
   "metadata": {},
   "source": [
    "<h2>Start Spark Session - Visual NLP, Healthcare NLP, Spark-NLP</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b8c5d2-49da-408a-a151-c0474bf9bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkocr import start\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "license = \"\"\n",
    "\n",
    "if license and \"json\" in license:\n",
    "\n",
    "    with open(license, \"r\") as creds_in:\n",
    "        creds = json.loads(creds_in.read())\n",
    "\n",
    "        for key in creds.keys():\n",
    "            os.environ[key] = creds[key]\n",
    "else:\n",
    "    raise Exception(\"License JSON File is not specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699825f-5d8c-4794-8c5a-e5cbb6cdf174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extra_configurations = {\n",
    "    \"spark.extraListeners\": \"com.johnsnowlabs.license.LicenseLifeCycleManager\", #required\n",
    "    \"spark.sql.legacy.allowUntypedScalaUDF\" : \"true\", #required\n",
    "    \"spark.executor.instances\" : \"7\", #change as per system\n",
    "    \"spark.executor.cores\" : \"16\", #change as per system\n",
    "    \"spark.executor.memory\" : \"130G\", #change as per system\n",
    "    \"spark.driver.memory\" : \"100G\", #change as per system\n",
    "    \"spark.sql.shuffle.partitions\" : \"896\" #change as per system\n",
    "}\n",
    "\n",
    "# Not needed for Google Collab\n",
    "# os.environ['JAVA_HOME'] = '/home/linuxbrew/.linuxbrew/Cellar/openjdk@17/17.0.15'\n",
    "\n",
    "spark = start(secret=os.environ.get(\"SPARK_OCR_SECRET\"),\n",
    "              nlp_secret=os.environ.get(\"SECRET\"),\n",
    "              nlp_internal=True,\n",
    "              nlp_jsl=True,\n",
    "              nlp_version=os.environ.get(\"PUBLIC_VERSION\"),\n",
    "              extra_conf=extra_configurations)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8362bb4-14c8-4ada-89ca-3ba15bb1a2df",
   "metadata": {},
   "source": [
    "<h2>Import Visual NLP, Healthcare NLP and Spark-NLP</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61d21ee-84b0-4846-b73d-66846b8f3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#Pyspark Imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Necessary imports from Spark OCR library\n",
    "import sparkocr\n",
    "from sparkocr import start\n",
    "from sparkocr.transformers import *\n",
    "from sparkocr.enums import *\n",
    "from sparkocr.utils import *\n",
    "\n",
    "# import sparknlp packages\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "from sparknlp_jsl.annotator import *\n",
    "from collections import Counter\n",
    "from sparknlp.pretrained import PretrainedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dc6b6905-7d7f-425b-b71c-b60b28d15b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(SOURCE_GT_PATH, DF_SAVE_PATH, SAVE_MAPPING_PATH):\n",
    "    \"\"\"\n",
    "    Method to Calculate Precision, Recall and F1-Score\n",
    "    Saves final file with prediction, ground truth, precision, recall\n",
    "    \"\"\"\n",
    "    \n",
    "    def calculate_metrics(preds, gts):\n",
    "      gt_counter = Counter(gts)\n",
    "      pred_counter = Counter(preds)\n",
    "\n",
    "      tp = 0\n",
    "      for item in pred_counter:\n",
    "          if item in gt_counter:\n",
    "              tp += min(pred_counter[item], gt_counter[item])\n",
    "\n",
    "      fp = sum(pred_counter.values()) - tp\n",
    "      fn = sum(gt_counter.values()) - tp\n",
    "\n",
    "      precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "      recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "\n",
    "      return precision, recall\n",
    "\n",
    "    with open(SOURCE_GT_PATH, \"r\") as f:\n",
    "        ground_truth = json.load(f)\n",
    "\n",
    "    df_predictions = spark.read.format(\"parquet\").load(DF_SAVE_PATH)\n",
    "\n",
    "    predictions_by_file = {}\n",
    "\n",
    "    for row in df_predictions.select(\"path\").distinct().toLocalIterator():\n",
    "        file_path = row.asDict()[\"path\"]\n",
    "        filename = os.path.basename(file_path)\n",
    "\n",
    "        if filename not in ground_truth:\n",
    "            continue\n",
    "\n",
    "        extracted_results = []\n",
    "        rows = df_predictions.filter(F.col(\"path\") == file_path).select(\"positions_ner\")\n",
    "\n",
    "        for r in rows.toLocalIterator():\n",
    "            for ner in r.asDict()[\"positions_ner\"]:\n",
    "                extracted_results.append(ner.asDict()[\"result\"])\n",
    "\n",
    "        predictions_by_file[filename] = extracted_results\n",
    "\n",
    "    summary = {}\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "\n",
    "    for filename, predictions in predictions_by_file.items():\n",
    "        gt_values = ground_truth[filename]\n",
    "        precision, recall = calculate_metrics(predictions, gt_values)\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "\n",
    "        summary[filename] = {\n",
    "            \"precision\": round(precision, 4),\n",
    "            \"recall\": round(recall, 4),\n",
    "            \"gt\": gt_values,\n",
    "            \"pred\": predictions\n",
    "        }\n",
    "\n",
    "        print(f\"Filename: {filename} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "\n",
    "    avg_precision = round(sum(all_precisions) / len(all_precisions), 4)\n",
    "    avg_recall = round(sum(all_recalls) / len(all_recalls), 4)\n",
    "    f1_score = round(2 * (avg_precision * avg_recall) / (avg_precision + avg_recall), 4)\n",
    "\n",
    "    print(f\"\\nOverall Precision: {avg_precision}\")\n",
    "    print(f\"Overall Recall: {avg_recall}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "    with open(SAVE_MAPPING_PATH, \"w\") as f:\n",
    "        json.dump(summary, f, indent=4)\n",
    "\n",
    "    print(f\"Mapping File Saved To : {SAVE_MAPPING_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7595bef5-603c-4a0f-9ec1-94ec9523677c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HOSPITAL': 0.9,\n",
       " 'NAME': 0.9,\n",
       " 'DOCTOR': 0.9,\n",
       " 'PATIENT': 0.9,\n",
       " 'AGE': 0.9,\n",
       " 'ID': 0.9,\n",
       " 'MEDICALRECORD': 0.9,\n",
       " 'IDNUM': 0.9,\n",
       " 'COUNTRY': 0.9,\n",
       " 'LOCATION': 0.9,\n",
       " 'STREET': 0.9,\n",
       " 'STATE': 0.9,\n",
       " 'ZIP': 0.9,\n",
       " 'CONTACT': 0.9,\n",
       " 'PHONE': 0.9,\n",
       " 'DATE': 0.9}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ner Threshold\n",
    "ner_threshold = 0.90\n",
    "\n",
    "# OCR Output Threshold\n",
    "ocr_threshold = 70\n",
    "\n",
    "# Ner Whitelist Entites\n",
    "whitelist = ['HOSPITAL', 'NAME', 'DOCTOR', 'PATIENT', 'AGE', 'ID', 'MEDICALRECORD', 'IDNUM', 'COUNTRY', 'LOCATION', 'STREET', 'STATE', 'ZIP', 'CONTACT', 'PHONE', 'DATE']\n",
    "\n",
    "# Matcher is used for regex matching from already detected NER\n",
    "# NER threshold is used to select detected NER for matching\n",
    "matcherWhitelist = {i : ner_threshold for i in whitelist}\n",
    "matcherWhitelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2557e2-3f65-44bd-9c89-704c8f6caa7c",
   "metadata": {},
   "source": [
    "<h2>Define Pipeline</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b3c41d-3b45-4906-91ce-2de4fdc325a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf_to_image = PdfToImage() \\\n",
    "  .setInputCol(\"content\") \\\n",
    "  .setSplitNumBatch(10) \\\n",
    "  .setOutputCol(\"image_raw\") \\\n",
    "  .setImageType(ImageType.TYPE_3BYTE_BGR) \\\n",
    "  .setSplittingStategy(SplittingStrategy.FIXED_NUMBER_OF_PARTITIONS)\n",
    "\n",
    "ocr = ImageToText() \\\n",
    "    .setInputCol(\"image_raw\") \\\n",
    "    .setOutputCol(\"text\") \\\n",
    "    .setIgnoreResolution(False) \\\n",
    "    .setPageIteratorLevel(PageIteratorLevel.SYMBOL) \\\n",
    "    .setPageSegMode(PageSegmentationMode.SPARSE_TEXT) \\\n",
    "    .setWithSpaces(True) \\\n",
    "    .setKeepLayout(False) \\\n",
    "    .setConfidenceThreshold(70)\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "abbreviations = ['Bros', 'No', 'al', 'vs', 'etc', 'Fig', 'Dr', 'Prof', 'PhD', 'MD', 'Co', 'Corp', 'Inc', 'bros', 'VS', 'Vs', 'ETC', 'fig', 'dr', 'prof', 'PHD', 'phd', 'md', 'co', 'corp', 'inc', 'Jan', 'Feb', 'Mar', 'Apr', 'Jul', 'Aug', 'Sep', 'Sept', 'Oct', 'Nov', 'Dec', 'St', 'st', 'AM', 'PM', 'am', 'pm', 'e.g', 'f.e', 'i.e']\n",
    "sentence_detector = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"en\") \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\") \\\n",
    "    .setImpossiblePenultimates(abbreviations) \\\n",
    "    .setUseCustomBoundsOnly(False) \\\n",
    "    .setSplitLength(2147483647) \\\n",
    "    .setExplodeSentences(False)\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "regex_matcher = RegexMatcher()\\\n",
    "    .setInputCols(\"sentence\")\\\n",
    "    .setOutputCol(\"regex_chunk\")\\\n",
    "    .setRules([\"(0?[1-9]|[12][0-9]|3[01])/(0?[1-9]|1[0-2])/\\d{4};DATE\",\n",
    "               \"\\d{3}-\\d{2}-\\d{4};IDNUM\",\n",
    "               \"\\(\\d{3}\\)\\s\\d{3}-\\d{4};PHONE\",\n",
    "               \"HOSP\\d{8};IDNUM\",\n",
    "               \"DR[A-Za-z0-9]{5,6};ID\"])\\\n",
    "    .setDelimiter(\";\")\n",
    "\n",
    "ner_docwise_large = PretrainedZeroShotNER().pretrained(\"zeroshot_ner_deid_subentity_docwise_large\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols(\"sentence\", \"token\") \\\n",
    "    .setOutputCol(\"ner_docwise_large\") \\\n",
    "    .setLabels([\"AGE\", \"CITY\", \"COUNTRY\", \"DATE\", \"DOCTOR\", \"HOSPITAL\", \"IDNUM\", \"ORGANIZATION\",\"PATIENT\", \"PHONE\", \"PROFESSION\", \"STATE\", \"STREET\", \"ZIP\"])\n",
    "\n",
    "ner_chunk_docwise_large = NerConverterInternal() \\\n",
    "    .setInputCols(\"sentence\", \"token\", \"ner_docwise_large\") \\\n",
    "    .setOutputCol(\"ner_chunk_docwise_large\") \\\n",
    "    .setThreshold(0.90)\n",
    "\n",
    "chunk_merger = ChunkMergeApproach() \\\n",
    "    .setInputCols('regex_chunk', 'ner_chunk_docwise_large') \\\n",
    "    .setOutputCol('merged_ner_chunk') \\\n",
    "    .setMergeOverlapping(True)\n",
    "\n",
    "deid_obfuscated = DeIdentification() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"merged_ner_chunk\"]) \\\n",
    "    .setOutputCol(\"obfuscated\") \\\n",
    "    .setMode(\"obfuscate\") \\\n",
    "    .setKeepMonth(True) \\\n",
    "    .setKeepYear(True) \\\n",
    "    .setObfuscateDate(True) \\\n",
    "    .setSameEntityThreshold(0.7) \\\n",
    "    .setKeepTextSizeForObfuscation(True) \\\n",
    "    .setFakerLengthOffset(2) \\\n",
    "    .setReturnEntityMappings(True) \\\n",
    "    .setDays(2) \\\n",
    "    .setMappingsColumn(\"aux\") \\\n",
    "    .setIgnoreRegex(True) \\\n",
    "    .setGroupByCol(\"path\") \\\n",
    "    .setRegion(\"us\") \\\n",
    "    .setSeed(40) \\\n",
    "    .setConsistentObfuscation(True) \\\n",
    "    .setChunkMatching(matcherWhitelist)\n",
    "\n",
    "cleaner = NerOutputCleaner() \\\n",
    "    .setInputCol(\"aux\") \\\n",
    "    .setOutputCol(\"new_aux\") \\\n",
    "    .setOutputNerCol(\"positions_ner\")\n",
    "\n",
    "position_finder = PositionFinder() \\\n",
    "    .setInputCols(\"positions_ner\") \\\n",
    "    .setOutputCol(\"coordinates\") \\\n",
    "    .setPageMatrixCol(\"positions\")\n",
    "\n",
    "draw_regions = ImageDrawRegions() \\\n",
    "  .setInputCol(\"image_raw\") \\\n",
    "  .setInputRegionsCol(\"coordinates\") \\\n",
    "  .setRectColor(Color.black) \\\n",
    "  .setFilledRect(True) \\\n",
    "  .setOutputCol(\"image_with_regions\")\n",
    "\n",
    "stages = [\n",
    "    pdf_to_image,\n",
    "    ocr,\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    regex_matcher,\n",
    "    ner_docwise_large,\n",
    "    ner_chunk_docwise_large,\n",
    "    chunk_merger,\n",
    "    deid_obfuscated,\n",
    "    cleaner,\n",
    "    position_finder,\n",
    "    draw_regions\n",
    "]\n",
    "\n",
    "pipe = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "df7469c8-dca6-43f7-b954-6c46e8afdc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PdfToImage_8dc5743ecb14,\n",
       " ImageToText_c39499abab3e,\n",
       " DocumentAssembler_d6e2031954fe,\n",
       " SentenceDetectorDLModel_c83c27f46b97,\n",
       " Tokenizer_d776e2e1fb9b,\n",
       " RegexMatcher_53482bca004d,\n",
       " PretrainedZeroShotNER_ca8c4dfe310f,\n",
       " NerConverterInternal_29475eb63ff9,\n",
       " ChunkMergeApproach_1c81c028c04e,\n",
       " DeIdentification_647e75912e36,\n",
       " NerOutputCleaner_d504cff86a0d,\n",
       " PositionFinder_2c179a047455,\n",
       " ImageDrawRegions_0550feeca735]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21317df0-aa3c-4375-b413-7d58112e663a",
   "metadata": {},
   "source": [
    "<h2>Easy Dataset</h2>\n",
    "<h4>Total Files : 30</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f3ea8639-d36a-4681-8251-0978eef462d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PDF_PATH = \"/workspace/PDF_FILES_EASY/*\"\n",
    "DF_SAVE_PATH = \"/workspace/easy/\"\n",
    "SOURCE_GT_PATH = \"/workspace/pdf_deid_gts_easy.json\"\n",
    "SAVE_MAPPING_PATH = \"/workspace/easy_result_mapping.json\"\n",
    "SAVE_OUTPUT_PDF = \"/workspace/easy_pdf_output/\"\n",
    "\n",
    "os.makedirs(SAVE_OUTPUT_PDF, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cfee1b-51aa-4a1c-ba95-ec259ca5915b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"binaryFile\").load(SOURCE_PDF_PATH)\n",
    "result = pipe.fit(df).transform(df)\n",
    "result.write.format('parquet').mode('overwrite').save(DF_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "83a5c38a-97be-4301-9af4-1fadd6701375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: PDF_Deid_Deidentification_21.pdf | Precision: 1.0000 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_5.pdf | Precision: 0.9302 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_9.pdf | Precision: 0.9091 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_16.pdf | Precision: 0.9111 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_11.pdf | Precision: 1.0000 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_4.pdf | Precision: 0.9756 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_6.pdf | Precision: 0.9756 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_2.pdf | Precision: 0.9302 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_24.pdf | Precision: 0.9524 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_15.pdf | Precision: 0.9286 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_12.pdf | Precision: 0.8222 | Recall: 0.9487\n",
      "Filename: PDF_Deid_Deidentification_10.pdf | Precision: 0.8125 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_29.pdf | Precision: 0.8667 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_3.pdf | Precision: 0.9302 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_27.pdf | Precision: 0.9524 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_8.pdf | Precision: 0.8889 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_14.pdf | Precision: 0.7111 | Recall: 0.9697\n",
      "Filename: PDF_Deid_Deidentification_22.pdf | Precision: 0.9756 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_19.pdf | Precision: 0.8696 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_1.pdf | Precision: 0.8889 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_7.pdf | Precision: 0.9512 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_28.pdf | Precision: 0.8478 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_18.pdf | Precision: 0.8750 | Recall: 0.8974\n",
      "Filename: PDF_Deid_Deidentification_0.pdf | Precision: 1.0000 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_17.pdf | Precision: 0.8511 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_20.pdf | Precision: 0.9286 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_25.pdf | Precision: 0.8667 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_23.pdf | Precision: 0.8298 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_26.pdf | Precision: 1.0000 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_13.pdf | Precision: 0.8511 | Recall: 0.9756\n",
      "\n",
      "Overall Precision: 0.9077\n",
      "Overall Recall: 0.9711\n",
      "F1 Score: 0.9383\n",
      "Mapping File Saved To : /workspace/easy_result_mapping.json\n"
     ]
    }
   ],
   "source": [
    "evaluate_predictions(SOURCE_GT_PATH=SOURCE_GT_PATH, DF_SAVE_PATH=DF_SAVE_PATH, SAVE_MAPPING_PATH=SAVE_MAPPING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c7092643-ee66-482a-ac8f-431b74f5be25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4236:>                                                       (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "OBFUSCATED_IMAGE_COL = \"image_with_regions\"\n",
    "\n",
    "img_to_pdf = ImageToPdf() \\\n",
    "    .setPageNumCol(\"pagenum\") \\\n",
    "    .setOriginCol(\"path\") \\\n",
    "    .setOutputCol(\"pdf\") \\\n",
    "    .setInputCol(OBFUSCATED_IMAGE_COL) \\\n",
    "    .setAggregatePages(True)\n",
    "\n",
    "source = spark.read.format(\"parquet\").load(DF_SAVE_PATH)\n",
    "result_pdf = img_to_pdf.transform(source)\n",
    "\n",
    "for row in result_pdf.select(\"path\", \"pdf\").toLocalIterator():\n",
    "  filename = row.asDict()[\"path\"]\n",
    "  basename = os.path.basename(filename)\n",
    "\n",
    "  savename = os.path.join(SAVE_OUTPUT_PDF, basename)\n",
    "    \n",
    "  pdfFile = open(savename, \"wb\")\n",
    "  pdfFile.write(row.asDict()[\"pdf\"])\n",
    "  pdfFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b1150b-fe7e-4e98-b74c-6c89f35a294a",
   "metadata": {},
   "source": [
    "<h2>Medium Dataset</h2>\n",
    "<h4>Total Files : 40 [ 30 Easy + 10 Medium ]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "baa66599-eec8-4d28-880c-887c45795888",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PDF_PATH = \"/workspace/PDF_FILES_MEDIUM/*\"\n",
    "DF_SAVE_PATH = \"/workspace/medium/\"\n",
    "SOURCE_GT_PATH = \"/workspace/pdf_deid_gts_medium.json\"\n",
    "SAVE_MAPPING_PATH = \"/workspace/medium_result_mapping.json\"\n",
    "SAVE_OUTPUT_PDF = \"/workspace/medium_pdf_output/\"\n",
    "\n",
    "os.makedirs(SAVE_OUTPUT_PDF, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff6315-fc85-4eec-8185-921a5b9f2f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"binaryFile\").load(SOURCE_PDF_PATH)\n",
    "result = pipe.fit(df).transform(df)\n",
    "result.write.format('parquet').mode('overwrite').save(DF_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fc836b6b-aec8-4499-9f01-c62aaeb08ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: PDF_Deid_Deidentification_Medium_4.pdf | Precision: 0.9038 | Recall: 0.9038\n",
      "Filename: PDF_Deid_Deidentification_Medium_5.pdf | Precision: 0.8519 | Recall: 0.8846\n",
      "Filename: PDF_Deid_Deidentification_Medium_1.pdf | Precision: 0.8113 | Recall: 0.8269\n",
      "Filename: PDF_Deid_Deidentification_Medium_2.pdf | Precision: 0.9318 | Recall: 0.7885\n",
      "Filename: PDF_Deid_Deidentification_Medium_9.pdf | Precision: 0.9200 | Recall: 0.8846\n",
      "Filename: PDF_Deid_Deidentification_Medium_8.pdf | Precision: 0.8302 | Recall: 0.8462\n",
      "Filename: PDF_Deid_Deidentification_Medium_3.pdf | Precision: 0.9216 | Recall: 0.9038\n",
      "Filename: PDF_Deid_Deidentification_Medium_7.pdf | Precision: 0.7778 | Recall: 0.8077\n",
      "Filename: PDF_Deid_Deidentification_Medium_6.pdf | Precision: 0.7458 | Recall: 0.8462\n",
      "Filename: PDF_Deid_Deidentification_Medium_0.pdf | Precision: 0.8431 | Recall: 0.8269\n",
      "Filename: PDF_Deid_Deidentification_6.pdf | Precision: 0.9756 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_26.pdf | Precision: 1.0000 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_16.pdf | Precision: 0.9111 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_20.pdf | Precision: 0.9286 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_8.pdf | Precision: 0.8889 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_10.pdf | Precision: 0.8125 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_19.pdf | Precision: 0.8696 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_28.pdf | Precision: 0.8478 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_9.pdf | Precision: 0.9091 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_2.pdf | Precision: 0.9302 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_18.pdf | Precision: 0.8750 | Recall: 0.8974\n",
      "Filename: PDF_Deid_Deidentification_14.pdf | Precision: 0.7111 | Recall: 0.9697\n",
      "Filename: PDF_Deid_Deidentification_23.pdf | Precision: 0.8298 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_7.pdf | Precision: 0.9512 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_0.pdf | Precision: 1.0000 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_4.pdf | Precision: 0.9756 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_22.pdf | Precision: 0.9756 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_29.pdf | Precision: 0.8667 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_3.pdf | Precision: 0.9302 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_11.pdf | Precision: 1.0000 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_1.pdf | Precision: 0.8889 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_13.pdf | Precision: 0.8511 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_17.pdf | Precision: 0.8511 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_24.pdf | Precision: 0.9524 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_15.pdf | Precision: 0.9286 | Recall: 0.9512\n",
      "Filename: PDF_Deid_Deidentification_5.pdf | Precision: 0.9302 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_21.pdf | Precision: 1.0000 | Recall: 1.0000\n",
      "Filename: PDF_Deid_Deidentification_12.pdf | Precision: 0.8222 | Recall: 0.9487\n",
      "Filename: PDF_Deid_Deidentification_27.pdf | Precision: 0.9524 | Recall: 0.9756\n",
      "Filename: PDF_Deid_Deidentification_25.pdf | Precision: 0.8667 | Recall: 0.9512\n",
      "\n",
      "Overall Precision: 0.8942\n",
      "Overall Recall: 0.9413\n",
      "F1 Score: 0.9171\n",
      "Mapping File Saved To : /workspace/medium_result_mapping.json\n"
     ]
    }
   ],
   "source": [
    "evaluate_predictions(SOURCE_GT_PATH=SOURCE_GT_PATH, DF_SAVE_PATH=DF_SAVE_PATH, SAVE_MAPPING_PATH=SAVE_MAPPING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "22191166-5e29-415c-82dd-e9e8a25a1924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4204:>                                                       (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "OBFUSCATED_IMAGE_COL = \"image_with_regions\"\n",
    "\n",
    "img_to_pdf = ImageToPdf() \\\n",
    "    .setPageNumCol(\"pagenum\") \\\n",
    "    .setOriginCol(\"path\") \\\n",
    "    .setOutputCol(\"pdf\") \\\n",
    "    .setInputCol(OBFUSCATED_IMAGE_COL) \\\n",
    "    .setAggregatePages(True)\n",
    "\n",
    "source = spark.read.format(\"parquet\").load(DF_SAVE_PATH)\n",
    "result_pdf = img_to_pdf.transform(source)\n",
    "\n",
    "for row in result_pdf.select(\"path\", \"pdf\").toLocalIterator():\n",
    "  filename = row.asDict()[\"path\"]\n",
    "  basename = os.path.basename(filename)\n",
    "\n",
    "  savename = os.path.join(SAVE_OUTPUT_PDF, basename)\n",
    "    \n",
    "  if \"Medium\" in filename:\n",
    "      pdfFile = open(savename, \"wb\")\n",
    "      pdfFile.write(row.asDict()[\"pdf\"])\n",
    "      pdfFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4b886-bf43-4eb1-a009-00c606533fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
